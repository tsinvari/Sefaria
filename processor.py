import json
import re
import requests
from typing import Dict, Optional
# from datetime import datetime # Removed, not used

# -------------------------------
# ğŸ”  Tractate and Reference Helpers
# -------------------------------

def get_tractate_names_map() -> Dict[str, str]:
    """Returns a dictionary mapping English tractate names to their Hebrew equivalents."""
    return {
        "Berakhot": "×‘×¨×›×•×ª", "Brachot": "×‘×¨×›×•×ª", "Peah": "×¤××”", "Demai": "×“×××™", "Kilayim": "×›×œ××™×",
        "Sheviit": "×©×‘×™×¢×™×ª", "Terumot": "×ª×¨×•××•×ª", "Maasrot": "××¢×©×¨×•×ª", "Maaser Sheni": "××¢×©×¨ ×©× ×™",
        "Challah": "×—×œ×”", "Orlah": "×¢×¨×œ×”", "Bikkurim": "×‘×™×›×•×¨×™×", "Shabbat": "×©×‘×ª",
        "Eruvin": "×¢×™×¨×•×‘×™×Ÿ", "Pesachim": "×¤×¡×—×™×", "Shekalim": "×©×§×œ×™×", "Yoma": "×™×•××",
        "Sukkah": "×¡×•×›×”", "Beitzah": "×‘×™×¦×”", "Rosh Hashanah": "×¨××© ×”×©× ×”", "Taanit": "×ª×¢× ×™×ª",
        "Ta'anit": "×ª×¢× ×™×ª", "Megillah": "××’×™×œ×”", "Moed Katan": "××•×¢×“ ×§×˜×Ÿ", "Chagigah": "×—×’×™×’×”",
        "Yevamot": "×™×‘××•×ª", "Ketubot": "×›×ª×•×‘×•×ª", "Nedarim": "× ×“×¨×™×", "Nazir": "× ×–×™×¨",
        "Sotah": "×¡×•×˜×”", "Gittin": "×’×™×˜×™×Ÿ", "Kiddushin": "×§×™×“×•×©×™×Ÿ",
        "Bava Kamma": "×‘×‘× ×§××", "Bava Metzia": "×‘×‘× ××¦×™×¢×", "Bava Batra": "×‘×‘× ×‘×ª×¨×",
        "Sanhedrin": "×¡× ×”×“×¨×™×Ÿ", "Makkot": "××›×•×ª", "Shevuot": "×©×‘×•×¢×•×ª",
        "Eduyot": "×¢×“×™×•×ª", "Avodah Zarah": "×¢×‘×•×“×” ×–×¨×”", "Avot": "××‘×•×ª", "Horayot": "×”×•×¨×™×•×ª",
        "Zevachim": "×–×‘×—×™×", "Menachot": "×× ×—×•×ª", "Chullin": "×—×•×œ×™×Ÿ", "Bekhorot": "×‘×›×•×¨×•×ª",
        "Arakhin": "×¢×¨×›×™×Ÿ", "Temurah": "×ª××•×¨×”", "Keritot": "×›×¨×™×ª×•×ª", "Meilah": "××¢×™×œ×”",
        "Kinnim": "×§× ×™×", "Tamid": "×ª××™×“", "Middot": "××“×•×ª", "Kelim": "×›×œ×™×",
        "Oholot": "××”×œ×•×ª", "Negaim": "× ×’×¢×™×", "Parah": "×¤×¨×”", "Tohorot": "×˜×”×¨×•×ª",
        "Mikvaot": "××§×•××•×ª", "Niddah": "× ×“×”", "Makhshirin": "××›×©×™×¨×™×Ÿ", "Zavim": "×–×‘×™×",
        "Tevul Yom": "×˜×‘×•×œ ×™×•×", "Yadayim": "×™×“×™×", "Uktzin": "×¢×•×§×¦×™×Ÿ",
        "Mo'ed Katan": "××•×¢×“ ×§×˜×Ÿ"
    }

def get_hebrew_daf_from_number(daf_number_str: str) -> str:
    """Converts a Latin number string (e.g., '5') to a Hebrew Gematria daf string (e.g., '×”')."""
    gematria = {
        1: '×', 2: '×‘', 3: '×’', 4: '×“', 5: '×”', 6: '×•', 7: '×–', 8: '×—', 9: '×˜',
        10: '×™', 20: '×›', 30: '×œ', 40: '×', 50: '× ', 60: '×¡', 70: '×¢', 80: '×¤', 90: '×¦',
        100: '×§', 200: '×¨', 300: '×©', 400: '×ª'
    }
    num = int(daf_number_str)
    if num <= 0:
        return ""
    hebrew_str = ""
    for value in sorted(gematria.keys(), reverse=True):
        while num >= value:
            hebrew_str += gematria[value]
            num -= value
    return hebrew_str.replace("×™×”", "×˜×•").replace("×™×•", "×˜×–")

# -------------------------------
# ğŸŒ Sefaria API Integration
# -------------------------------

def get_sefaria_data(daf_reference: str) -> Dict[str, str]:
    """Queries Sefaria API to get canonical link and the first line of text in both English and Hebrew."""
    default_response = {"sefaria_link": "", "text_en": "", "text_he": ""}
    if not daf_reference:
        return default_response

    try:
        api_ref = f"{daf_reference.replace(' ', '.')}:1"
        api_url = f"https://www.sefaria.org/api/texts/{api_ref}"
        response = requests.get(api_url)
        response.raise_for_status()
        data = response.json()

        canonical_ref_full = data.get("ref")
        sefaria_link = ""
        if canonical_ref_full:
            canonical_ref = canonical_ref_full.rsplit(':', 1)[0]
            sefaria_link = f"https://www.sefaria.org/{canonical_ref.replace(' ', '_')}"
            print(f"      ğŸ”— Found Sefaria link: {sefaria_link}")

        text_en = data.get("text", "")
        text_he = data.get("he", "")
        text_en_clean = re.sub('<[^<]+?>', '', text_en[0]).strip() if isinstance(text_en, list) and text_en else ""
        text_he_clean = re.sub('<[^<]+?>', '', text_he[0]).strip() if isinstance(text_he, list) and text_he else ""

        return {
            "sefaria_link": sefaria_link,
            "text_en": text_en_clean,
            "text_he": text_he_clean
        }

    except requests.exceptions.RequestException as e:
        print(f"      âš ï¸ Could not fetch Sefaria data for '{daf_reference}'")
        return default_response

# -------------------------------
# ğŸ¥ YouTube Embed Helper
# -------------------------------

def get_youtube_embed_url(url: str) -> str:
    """Extracts YouTube video ID and formats it for embedding."""
    if not url:
        return ""
    regex = r"(?:https?:\/\/)?(?:www\.)?(?:youtube\.com\/(?:[^\/\n\s]+\/\S+\/|(?:v|e(?:mbed)?)\/|\S*?[?&]v=)|youtu\.be\/)([a-zA-Z0-9_-]{11})"
    match = re.search(regex, url)
    return f"https://www.youtube.com/embed/{match.group(1)}?rel=0&showinfo=0" if match else ""

# -------------------------------
# ğŸ§© Core Processing Function
# -------------------------------

def process_prepared_data(input_file, daf_reaction_output_file, non_daf_reaction_output_file, limit: Optional[int] = None):
    """Reads prepared data, processes 'Daf Reaction' videos, and confirms 'non-Daf' classifications interactively."""
    print(f"\nğŸ“˜ Loading data from: {input_file}")

    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            prepared_data = json.load(f)
    except FileNotFoundError:
        print(f"âŒ Error: Input file not found: {input_file}")
        print("Please ensure the file from Script 1 is in the same directory.")
        return
    except json.JSONDecodeError:
        print(f"âŒ Error: Could not decode JSON from '{input_file}'.")
        return
    except Exception as e:
        print(f"âŒ Error reading input file: {e}")
        return

    if limit:
        prepared_data = prepared_data[:limit]
        print(f"âš™ï¸ Limiting run to the first {limit} items.\n")

    tractate_map = get_tractate_names_map()
    pattern = re.compile(rf'({"|".join(re.escape(k) for k in tractate_map)})\s+(\d{{1,3}})([ab])?\b', re.IGNORECASE)

    daf_reaction_data = []
    non_daf_reaction_data = []

    print(f"ğŸš€ Processing {len(prepared_data)} video entries...\n")

    for idx, item in enumerate(prepared_data, start=1):
        original_title = item.get("title", "")
        if not original_title:
            continue

        print(f"\n{'-'*80}")
        print(f"ğŸï¸  [{idx}] {original_title}")
        print(f"{'-'*80}")

        is_daf_reaction = (
                            "daf reaction" in original_title.lower() or
                            "#dafreaction" in original_title.lower()
                        )

        if is_daf_reaction:
            print("ğŸ§© Detected as Daf Reaction.")
            
            # --- FIX 1: Handle potential NoneType ---
            original_description = item.get("paragraph") or ""
            # ----------------------------------------
            
            processed_item = {
                "daf_reference": "",
                "daf_reference_he": "",
                "original_title": original_title,
                "youtube_url": item.get("youtube_url"),
                "youtube_embed": get_youtube_embed_url(item.get("youtube_url")),
                "sefaria_link": "",
                "paragraph": original_description,
                "text_en": "",
                "text_he": ""
            }

            search_text = (original_title + " " + original_description).replace("â€™", "'").replace("â€", "'")
            match = pattern.search(search_text)
            if match:
                tractate_en_raw = match.group(1)
                daf_number = match.group(2)
                daf_side = match.group(3)
                canonical_tractate_en = next((k for k in tractate_map if k.lower() == tractate_en_raw.lower()), tractate_en_raw)
                canonical_tractate_en = canonical_tractate_en.replace(" ", "_").replace("'", "")
                daf_reference_en = f"{canonical_tractate_en} {daf_number}{daf_side or 'a'}"
                daf_reference_he = f"{tractate_map.get(canonical_tractate_en, '')} {get_hebrew_daf_from_number(daf_number)} {'×‘' if daf_side == 'b' else '×'}"

                print(f"    ğŸ“– Found daf reference: {daf_reference_en} | {daf_reference_he}")
                sefaria_data = get_sefaria_data(daf_reference_en)

                processed_item.update({
                    "daf_reference": daf_reference_en,
                    "daf_reference_he": daf_reference_he,
                    "sefaria_link": sefaria_data["sefaria_link"],
                    "text_en": sefaria_data["text_en"],
                    "text_he": sefaria_data["text_he"]
                })
            else:
                print("    âš ï¸ No daf reference found in text.")

            daf_reaction_data.append(processed_item)

        else:
            # --- FIX 2: Add y/n prompt to correctly sort files ---
            print("    âš ï¸ Item not detected as 'Daf Reaction'.")
            reclassify = input("    -> Manually reclassify as Daf Reaction? (y/n): ").strip().lower()
            
            if reclassify == 'y':
                print("    ğŸ” Reclassified as Daf Reaction (manual override).")

                # Prompt user to provide daf reference manually if missing
                manual_ref = input("    ğŸ§¾ Enter daf reference (e.g., 'Berakhot 2a') or press Enter to skip: ").strip()

                sefaria_data = {"sefaria_link": "", "text_en": "", "text_he": ""}
                daf_reference_en = ""
                daf_reference_he = ""

                if manual_ref:
                    # Try to find the matching Hebrew name and daf side
                    match = re.match(r"([\w\s']+)\s+(\d{1,3})([ab])?", manual_ref)
                    if match:
                        tractate_en_raw = match.group(1).strip()
                        daf_number = match.group(2)
                        daf_side = match.group(3) or "a"
                        # tractate_map is already loaded
                        canonical_tractate_en = next((k for k in tractate_map if k.lower() == tractate_en_raw.lower()), tractate_en_raw)
                        daf_reference_en = f"{canonical_tractate_en} {daf_number}{daf_side}"
                        daf_reference_he = f"{tractate_map.get(canonical_tractate_en, '')} {get_hebrew_daf_from_number(daf_number)} {'×‘' if daf_side == 'b' else '×'}"
                        print(f"      ğŸ“˜ Using manual daf reference: {daf_reference_en} | {daf_reference_he}")
                        sefaria_data = get_sefaria_data(daf_reference_en)
                    else:
                        print("      âš ï¸ Could not parse manual reference format. Skipping Sefaria lookup.")
                else:
                    print("      âš ï¸ No daf reference provided. Skipping Sefaria lookup.")

                processed_item = {
                    "daf_reference": daf_reference_en,
                    "daf_reference_he": daf_reference_he,
                    "original_title": original_title,
                    "youtube_url": item.get("youtube_url"),
                    "youtube_embed": get_youtube_embed_url(item.get("youtube_url")),
                    "sefaria_link": sefaria_data.get("sefaria_link", ""),
                    "paragraph": item.get("paragraph") or "", # Also fix NoneType here
                    "text_en": sefaria_data.get("text_en", ""),
                    "text_he": sefaria_data.get("text_he", "")
                }
                # Add to the *Daf Reaction* list
                daf_reaction_data.append(processed_item)
            
            else:
                # If 'n' or anything else, add the original item to the *non-Daf* list
                print("    ğŸš« Skipped. Adding to non-Daf Reaction file.")
                non_daf_reaction_data.append(item)
            # --- END OF FIX 2 ---


    # -------------------------------
    # ğŸ’¾ Save Results
    # -------------------------------
    try:
        with open(daf_reaction_output_file, 'w', encoding='utf-8') as f:
            json.dump(daf_reaction_data, f, indent=4, ensure_ascii=False)
        print(f"\nâœ… Saved {len(daf_reaction_data)} Daf Reaction entries â†’ {daf_reaction_output_file}")
    except Exception as e:
        print(f"âŒ Error saving Daf Reaction file: {e}")

    try:
        with open(non_daf_reaction_output_file, 'w', encoding='utf-8') as f:
            json.dump(non_daf_reaction_data, f, indent=4, ensure_ascii=False)
        print(f"âœ… Saved {len(non_daf_reaction_data)} non-Daf Reaction entries â†’ {non_daf_reaction_output_file}")
    except Exception as e:
        print(f"âŒ Error saving non-Daf Reaction file: {e}")


# -------------------------------
# ğŸ Script Entry Point
# -------------------------------

if __name__ == "__main__":
    INPUT_JSON_FILE = "2025-11-04_preparedata_Dafreactions.json"
    OUTPUT_DAF_FILE = "2025-11-04_processed_data_Dafreactions.json"
    OUTPUT_NON_DAF_FILE = "2025-11-04_notdafreaction.json"

    print("\nğŸ“‚ Sefaria Classification Processor")
    print("========================================")
    
    # Added a check to see if the input file exists before starting
    try:
        with open(INPUT_JSON_FILE, 'r', encoding='utf-8') as f:
            pass # Just check if it can be opened
        print(f"Found input file: {INPUT_JSON_FILE}\n")
    except FileNotFoundError:
        print(f"âŒ ERROR: Input file not found: {INPUT_JSON_FILE}")
        print("Please make sure the file from Script 1 is in the same directory and named correctly.")
        exit() # Exit the script if no input file is found
        
    print("Options:")
    print("  1ï¸âƒ£  Process entire JSON file")
    print("  2ï¸âƒ£  Process first 10 items (for testing)")
    choice = input("\nEnter choice (1 or 2): ").strip()

    limit = 20 if choice == '2' else None
    process_prepared_data(INPUT_JSON_FILE, OUTPUT_DAF_FILE, OUTPUT_NON_DAF_FILE, limit)